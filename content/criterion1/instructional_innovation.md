---
title: Instructional Innovation
linktitle: Instructional Innovation
toc: true
type: docs
date: "2021-01-15"
draft: false
menu:
  crit1:
    parent: Teaching Effectiveness
    weight: 1

# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 1
---

The evolution of my STAT 110 Fundamentals of Statistics curriculum good
illustration of my approach to blending instructional innovation and the
assessment of student learning. STAT 110 is ripe for a discussion of
instructional innovation tied to the assessment of student learning due to
the demand and large sections (37 versus 25), which has translated
into an opportunity to teach the course in multiple formats, be it
face-to-face in the classroom, online asynchronously over the summer, or in
an online synchronous format due to COVID-19.

### Overview

In this section, I will provide an overview of how the course material has
evolved from a face-to-face flipped classroom for STAT 110 and then
translating this material to synchronous and asynchronous online courses.

The face-to-face rendition of this course is built around the flipped
classroom, which is discussed in more depth in the section on [criterion
4]({{<ref "/criterion4/student_centered.md">}}), but I would like to highlight a few
of the related innovations here. First, I embedded self-assessment
multiple-choice questions in an online and interactive set of course notes,
allowing students to check their understanding and review the material
outside of class. Next, the transition from a face-to-face flipped class to
an online format is discussed. Finally, I will discuss innovations that
evolved out of trying to develop authentic assessments that can be translated to
multiple formats.

## Using Embedded Self-Assessments

{{< figure src="/img/book_MC.png" title="**Figure 1.** An example of an embedded self-assessment. Students receive immediate feedback after reading each section of the book, including guidance for incorrect responses. ">}}

In two of my previous courses, STAT 110 and STAT 489, I constructed online
textbooks to supplement instruction. One of the primary advantages of
creating a web-based textbook is the ability to embed videos and
multiple-choice problems directly in the text. The students are asked to use
these assessments to gauge their understanding of the material, providing
immediate feedback and allowing them to determine if they have understood the
relevant material.

These assessments are then used to prepare students for the end-of-module
assessments. Before wrapping up each module with a suite of larger
assessments, students are given a short quiz that consists of a random
selection of these book problems in hopes of encouraging them to go back and
review the associated material.

> As part of student evaluations, students were prompted to comment on the online textbook. Here are some positive responses related to the embedded assessments.

> very useful. I liked the little multiple choice questions in the reading. 

> I liked this as well, with the check me quizzes and videos. Great resource for learning and exams 

> The online textbook was useful to help in giving course examples, and the questions aligned with the reading quizzes. 

> I found it useful in the way that practice questions were in there. 

> I found it useful especially the multiple choice questions embedded.

> I think the text book was very useful and i loved how they had multiple choice practice 

> I found the textbook extremely useful and liked the practice quizes/questions and videos. They helped me check my comprehension and also explained why I was wrong for some questions. a

Next, I will discuss the translation of the flipped classroom into an online format.

## The Implementation of and Online STAT 110

{{< figure src="/img/welcome.png" title="**Figure 2.** Students are welcomed to the first week of STAT 110, an asynchronous online course taught during each of the 2017-2020 summer terms.">}}

During the 2017 summer term, I had the opportunity to implement the first
online STAT 110 offering here at WSU. Since that time, STAT 110 has been
offered over multiple sections each summer term with an increasing demand
evidenced by the growing number of sections each year. There were several
challenges to adapting my materials to the online setting, which I will
summarize below. It should be noted that, in each case, the changes made in
anticipation of teaching online also greatly benefit

**Organizational Challenges.** As discussed in the section on [criterion 3]({{<ref
"/criterion3/continuing_education.md">}}), first took the WeTeach courses in
the spring of 2017 and then revisited (and finally completed) the course in
the summer of 2020. This curriculum has shaped my approach to this online
course, and in particular, has taught me the importance of organization
and focused communication.

Our summer offers are taught over eight weeks, which allowed for an easy
2-regular-weeks to 1-summer-week conversion and making it easy to map my
regular in-class activities to an online environment. The demands for better
organization forced me to rearrange the material into 8 modules, with one
module covered each week.  

To make navigating the various components of the course easier, I
instituted a common numbering scheme for the whole course. First,
everything is numbered according to the encompassing module. Second, the
numbers for the readings were aligned with the corresponding activity.
For example, students should work through Section 5.1 in the book;
watching videos, reading the text, and attempting the self-assessment
problems; before attempting Activity 5.1. Then they move on to Section
5.2 and Activity 5.2, and so forth.

**Translating in-class group activities.** Another challenge was adapting my
classroom learning activities, which are usually completed in groups, to an
online setting. The asynchronous nature of the course precluded asking the
students to work in groups, so I decided that I would do my best to mimic
this classroom experience with recorded videos. For each activity, I led
students through an example, occasionally providing small lecture components,
and then asked students to pause the video and complete additional exercises
on their own. When they restart the video, I would go over my solution and
discuss common mistakes.

The final challenge was implementing a robust online assessment scheme that
would give a meaningful and authentic assessment of student performance. It has
taking me years to implement a complete solution, which is discussed in the
next section.

## Taking advantage of randomized practice and end-of-module quizzes

{{< figure src="/img/quiz_scheme.png" title="**Figure 3.** After adapting my assessments to an online setting, the final scheme involves material divided into three areas with corresponding review and practice materials.">}}

When adapting my assessment materials to the online setting, I had three
motivating goals. First, I wanted to provide students with enough review and
practice to allow success while working on their own without support from
their peers. Second, I wanted to develop a scheme that took advantage of the
D2L features and allow for the quick turn around on feedback. Finally, I wanted
to fight academic dishonesty and get an authentic assessment of each
student's performance. 

The final implementation represents my best effort to balance and meet each
of these goals. The scheme consists of breaking assessment items into three
groups: knowledge-based assessments suitable to multiple-choice questions,
assessments of written interpretations, and checking computer skills. I will
discuss the reasoning for this split and the efficacy of my quiz scheme for
each of my original goals below.

**Preparation.** The scheme for individual review through namely embedded
questions, writing review materials, and JMP how-to videos. Next students are
asked to practice what they have learned through practice quizzes and
worksheets. A key feature of the multiple-choice practice quiz is that
questions are pulled at random from a large bank of similar questions, which
allows students additional practice by repeating the quiz.

**Prompt feedback.** By splitting the multiple-choice and written
quizzed questions into two separate quizzes allows for faster turn-around on
grading/feedback. D2L can automatically score the multiple-choice questions
these items and immediately provide students with their score, which wouldn't
be possible for quizzes that included short answer questions. I have also
found that I am more efficient in grading three short assessments consisting of
similar types of problems.

**Authentic assessments.** After encountering issues with too much student
collaboration on homework assignments, I move as much material to D2L quizzes
as possible. Furthermore, multiple-choice and written assessments both pull
questions from a random bank of similar problems, making it harder for
students to collaborate on the quizzes (they likely get different questions
sorted in a different order). Finally, I made use of the Respondus Lockdown
Browser & Monitor, which locks down the student's computer and records their
activity using the web camera. Together these changes make it is much harder
for students to cheat on these assessments and much more likely that I get an
authentic assessment of student learning.

Next, I will discuss a novel project I developed for STAT 310.

## A New Virtual Pilot Study for STAT 310

Recently STAT 310 was changed to a writing-intensive course and last
year, Dr. Tisha Hooks and I developed a project to facilitate
written reports. In this project, students work in groups to design and
implement an experiment on [The
Islands](http://smp-island.smp.uq.edu.au/index.php) (see **Figure 5**),
a virtual environment that provides a (fairly) authentic experience
working with human subjects. Students are required to gain a resident’s
consent before working with them and residents tend to drop
out of the study. Students are forced to think about realistic
expectations for measurable change over a short period, i.e. can
we expect a person’s IQ to change over a short period.
Finally, as in real life, obtaining a simple random sample is nearly
impossible and students are forced to design a reasonable (but flawed)
sampling scheme.


{{< figure src="/img/islands.png" title="**Figure 3.** The Islands is a virtual environment that allows students to conduct virtual experiments and studies. The three islands contain residents who can be found in their residence. After gaining consent, students can assign each resident a task as part of a larger study. ">}}


While the first run of the project was promising, one problem that both
Dr. Hooks and I observed was most experiments resulted in
non-significant results. Power is one of the main topics early covered
in STAT 310 and is directly related to this problem: the first round of
studies either was looking for differences too minute to detect or
didn’t have enough participants to detect a difference that was present.
When performing expensive real-world studies, it is customary to first
perform a small pilot study that has several advantages. First,
conducting the pilot study allows the researcher to determine the
feasibility of the design and find any unforeseen problems. Second—and
more importantly—the researcher uses the resulting data to estimate the
sample size needed to have a good chance of finding a significant
difference, i.e. the sample size needed for a specified power level.
This important step makes sure that a researcher doesn’t waste their
time and money on an impossible task or waste too much time and money on
unneeded replications on an easy question.

This project provides the perfect opportunity to introduce students to
pilot studies!

When redesigning this project, I started by reviewing the literature on
pilot studies, and found two very good articles to share with students.
In particular, Thabane et al. provide several resources,
including a detailed outline for reporting on a pilot study as seen in
**Figure 6**.

In the revised version of the projects, students still started by
working in a group to propose a study. After getting some feedback from
the instructor, each group was required to conduct a pilot study and
write up their results using the outline provided by Thabane et al. . In
particular, each group was required to perform and report on the power
analysis for their research question. Then all of the students in the
class ranked the proposals with the top 3 proposals receiving a bonus.
Students were instructed to pay particular attention to the power
analysis and the amount of work estimated for each prospective study.
Then the whole class conducted a larger study based on the winning
design, with the winning team in charge of managing the class’s work.
Finally, each student wrote a final report on the class’s results.

{{< figure src="/img/pilot_study.png" title=" **Figure 4.** Thabane et al. provide, among other things, a detailed outline for a pilot study; which I found a useful guide for student reports. ">}}

I was very pleased with the results of this project. I believe that
working with the Islands is a valuable and fun exercise, evidenced by
the student enthusiasm Dr. Hooks and I witnessed. Furthermore, I hope
that running the pilot study first gave the students real experience
with thinking about design feasibility and the importance of a power
analysis. Also, first writing about the pilot study and then writing about
the resulting main winning design offered the students a chance to see
two variations on reporting on a study; with each report tailored to the
goals of the respective design.

{{< figure src="/img/example_project.png" title=" **Figure 5.** The outcomes of one student project, where a randomized experiment was conducted to compare the effects of petting two types of animals to a baseline control.  As expected, petting a crocodile raises the average heart rate compared to the other two treatment groups.">}}

My colleague Dr. Tisha Hooks used this project in her subsequent STAT 310 courses, and her comments (taken from her [letter of support](/testimonial/hooks_letter_of_support.pdf/))

> STAT 310 recently became a writing intensive course. Todd put a lot of work
> into creating a writing project. Students were required to work in groups
> to choose a research question of interest and then conduct a pilot study to
> investigate that question in a virtual population known as The Islands. He
> found articles that provide > students with the basic knowledge needed to
> design a pilot study, created an assignment description and rubric, and found
> a way to make the project even more fun by encouraging competition amongst
> the students. Fortunately for me, he was willing to share his work so that
> I could use the same assignment in my sections. Overall, the STAT 310
> course is currently in a very good place, and once again, I have Todd to
> thank.